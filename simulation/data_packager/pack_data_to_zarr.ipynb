{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packing Data Into Provided Sample Zarr\n",
    "\n",
    "The point of this notebook is to package the simulation data I generated via Blender into the sample dataset Zarr tree that Cheng provided on his GitHub. This way, we can easily integrate the simulation into the existing data structure for training the tracking extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import zarr\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import pandas as pd\n",
    "from numcodecs import Blosc\n",
    "\n",
    "# Do some ugly path manipulation to find all packages\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "from simulation.io_util.image_io_util import read_uviz\n",
    "from simulation.common.projection import ray_length_to_zbuffer, zbuffer_to_pcloud\n",
    "from simulation.common.geometry_util import (barycentric_interpolation, get_aabb, get_union_aabb)\n",
    "from simulation.cloth_3d_util.util import quads2tris, axis_angle_to_matrix\n",
    "from simulation.common.igl_util import query_uv_barycentric\n",
    "from simulation.data_packager.cloth_3d_canonical_accessor import Cloth3DCanonicalAccessor\n",
    "\n",
    "# Trying to avoid this import as it will execute the Zarr packaging code as is.\n",
    "# from simulation.data_packager.smpl_cloth_zarr_v5_cheng import Cloth3DCanonicalAccessor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File root: /home/dcolli23/code/school/rob599_deeprob/projects/final/garmentnets_tracking/simulation/data_packager\n",
      "GarmentNets root: /home/dcolli23/code/school/rob599_deeprob/projects/final/garmentnets_tracking\n"
     ]
    }
   ],
   "source": [
    "FILE_ROOT = Path(os.getcwd())\n",
    "print(\"File root:\", FILE_ROOT)\n",
    "GARMENTNETS_ROOT = (FILE_ROOT / \"..\" / \"..\").absolute().resolve()\n",
    "print(\"GarmentNets root:\", GARMENTNETS_ROOT)\n",
    "SIM_DATASET_DIR = (FILE_ROOT / \"..\" / \"script_output\" / \"full_dataset_attempt_2\").absolute()\n",
    "CLOTH3D_PATH = Path(os.path.expanduser(\"~/DataLocker/datasets/CLOTH3D/training/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience function for debugging\n",
    "def print_nested_dict_types(d: dict):\n",
    "    keys_and_values = [(k, v, 0) for k, v in d.items()][::-1]\n",
    "    while len(keys_and_values) > 0:\n",
    "        key, val, level = keys_and_values.pop(-1)\n",
    "        # if\n",
    "        tabs = '\\t' * level\n",
    "        if isinstance(val, dict):\n",
    "            print(tabs + key)\n",
    "            for subkey, subval in val.items():\n",
    "                keys_and_values.append((subkey, subval, level + 1))\n",
    "        else:\n",
    "            print(tabs + key, type(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs:\n",
    "\n",
    "- I should read the Blend files so that I can calculate exactly what the change in position/velocity of the \"gripper\" is at each timestep.\n",
    "- Define interface for new Zarr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Zarr Interface\n",
    "\n",
    "```\n",
    "/\n",
    " └── Tshirt\n",
    "     ├── samples\n",
    "     │   ├── 00380_Tshirt_509\n",
    "     │   │   ├── image\n",
    "     │   │   │   ├── depth (4, 1024, 1024, 1) float16\n",
    "     │   │   │   ├── mask (4, 1024, 1024, 1) bool\n",
    "     │   │   │   ├── rgb (4, 1024, 1024, 3) uint8\n",
    "     │   │   │   └── uv (4, 1024, 1024, 2) float16\n",
    "     │   │   ├── misc\n",
    "     │   │   │   ├── cloth_aabb (2, 3) float32\n",
    "     │   │   │   ├── cloth_canonical_aabb (2, 3) float32\n",
    "     │   │   │   ├── cloth_canonical_verts (4762, 3) float32\n",
    "     │   │   │   ├── cloth_faces (4668, 4) uint16\n",
    "     │   │   │   ├── cloth_texture (2048, 2048, 3) uint8\n",
    "     │   │   │   ├── cloth_uv_faces (4668, 4) uint16\n",
    "     │   │   │   ├── cloth_uv_verts (4936, 2) float32\n",
    "     │   │   │   ├── cloth_verts (4762, 3) float32\n",
    "     │   │   │   ├── extrinsic_list (4, 4, 4) float32\n",
    "     │   │   │   ├── human_canonical_aabb (2, 3) float32\n",
    "     │   │   │   ├── human_faces (13776, 3) uint16\n",
    "     │   │   │   ├── human_verts (6890, 3) float32\n",
    "     │   │   │   └── intrinsic (3, 3) float32\n",
    "     │   │   ├── point_cloud\n",
    "     │   │   |   ├── canonical_point (91320, 3) float16\n",
    "     │   │   |   ├── point (91320, 3) float16\n",
    "     │   │   |   ├── rgb (91320, 3) uint8\n",
    "     │   │   |   ├── sizes (4,) int64\n",
    "     │   │   |   └── uv (91320, 2) float16\n",
    "     │   │   ├── dynamics_sequences\n",
    "     │   │   |   ├── 0\n",
    "     │   │   |   |   ├── image\n",
    "     |   |   |   |   |   ├── depth (num_frames, 1024, 1024, 1) float16\n",
    "     │   │   |   |   |   ├── mask (num_frames, 1024, 1024, 1) bool\n",
    "     │   │   |   |   |   ├── rgb (num_frames, 1024, 1024, 3) uint8\n",
    "     │   │   |   |   |   ├── uv (num_frames, 1024, 1024, 2) float16\n",
    "     │   │   |   |   ├── misc\n",
    "     │   │   |   |   |   ├── camera_used (1,) uint8\n",
    "     │   │   |   |   ├── point_cloud\n",
    "     │   │   |   |   |   ├── canonical_point (num_frames, num_points, 3) float16\n",
    "     │   │   |   |   |   ├── point (num_frames, num_points, 3) float16\n",
    "     │   │   |   |   |   ├── rgb (num_frames, num_points, 3) uint8\n",
    "     │   │   |   |   |   ├── sizes (num_frames, ) int64\n",
    "     │   │   |   |   |   ├── uv (num_frames, num_points, 2) float16\n",
    "     │   │   |   |   ├── control_input\n",
    "     │   │   |   |   |   ├── direction (num_frames, 3) float16\n",
    "     │   │   |   |   |   ├── velocity_meters_per_second (num_frames, ) float16\n",
    "     │   │   |   ├── 1 (same structure as '0' above) \n",
    "     │   │   |   ├── 2 (same structure as '0' above)\n",
    "     │   │   |   ├── 3 (same structure as '0' above)\n",
    "     │   │   |   ├── 4 (same structure as '0' above)\n",
    "```     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Output Zarr\n",
    "\n",
    "- Use `<zarr_node>.create_group('group_name')` to create a group at the current node (group)\n",
    "- Use `<var> = <group>.array(name='name', data=<your_numpy_array>)` to add an array to a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZARR_FILEPATH = GARMENTNETS_ROOT / \"data\" / \"garmentnets_tracking_simulation_dataset.zarr\"\n",
    "\n",
    "# r+ is read/write but the data must exist first.\n",
    "# mode = 'r'  # Use for debugging first.\n",
    "# mode = 'r+'\n",
    "# zr = zarr.open(ZARR_FILEPATH.as_posix(), mode=mode)\n",
    "compressor = Blosc(cname='zstd', clevel=6, shuffle=Blosc.BITSHUFFLE)\n",
    "\n",
    "categories = [\"Tshirt\"]\n",
    "rows = dict()\n",
    "for category in categories:\n",
    "    store = zarr.DirectoryStore(ZARR_FILEPATH / category)\n",
    "    root = zarr.group(store=store, overwrite=False)\n",
    "    sample_root = root.require_group('samples', overwrite=False)\n",
    "    summary_root = root.require_group('summary', overwrite=False)\n",
    "    rows[category] = {\n",
    "        'compressor': compressor,\n",
    "        'store': store,\n",
    "        'root': root,\n",
    "        'sample_root': sample_root,\n",
    "        'summary_root': summary_root\n",
    "    }\n",
    "datasets_df = pd.DataFrame(list(rows.values()), index=rows.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compressor</th>\n",
       "      <th>store</th>\n",
       "      <th>root</th>\n",
       "      <th>sample_root</th>\n",
       "      <th>summary_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tshirt</th>\n",
       "      <td>Blosc(cname='zstd', clevel=6, shuffle=BITSHUFF...</td>\n",
       "      <td>[.zgroup, summary/.zgroup, samples/.zgroup]</td>\n",
       "      <td>[samples, summary]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               compressor  \\\n",
       "Tshirt  Blosc(cname='zstd', clevel=6, shuffle=BITSHUFF...   \n",
       "\n",
       "                                              store                root  \\\n",
       "Tshirt  [.zgroup, summary/.zgroup, samples/.zgroup]  [samples, summary]   \n",
       "\n",
       "       sample_root summary_root  \n",
       "Tshirt          []           []  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Following Should Be Converted To A Function To Add A Single Sample's Simulations To Zarr\n",
    "\n",
    "This was taken from `smpl_cloth_zarr_v5_cheng.convert_experiment()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some debug variables that will eventually be used as function arguments.\n",
    "sample_dir = SIM_DATASET_DIR / \"00380_Tshirt_509\"\n",
    "\n",
    "# zarr configuration\n",
    "sample_root = sample_root  # Probably the \"Group\" at which this sample is located.\n",
    "compressor = compressor\n",
    "accessor = Cloth3DCanonicalAccessor(CLOTH3D_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metadata\n",
    "meta_path = sample_dir.joinpath('meta.pk')\n",
    "sim_result_path = sample_dir.joinpath('hanging_rest_state_results.pkl')\n",
    "meta = pickle.load(meta_path.open('rb'))\n",
    "sim_result = pickle.load(sim_result_path.open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera\n",
      "\textrinsic_list <class 'list'>\n",
      "\tintrinsic <class 'numpy.ndarray'>\n",
      "images\n",
      "\trgb <class 'list'>\n",
      "\tuviz <class 'list'>\n",
      "meta\n",
      "\tfabric <class 'str'>\n",
      "\tgender <class 'int'>\n",
      "\tgarment_name <class 'str'>\n",
      "\tsample_id <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print_nested_dict_types(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and read metadata\n",
    "cloth_verts = sim_result['cloth_state']['verts']\n",
    "cloth_faces = np.array(sim_result['cloth_state']['faces'])\n",
    "# CLOTH3D data has all quad faces\n",
    "assert(cloth_faces.shape[1] == 4)\n",
    "cloth_uv_verts = sim_result['cloth_state']['uv_verts']\n",
    "cloth_uv_faces = np.array(sim_result['cloth_state']['uv_faces'])\n",
    "assert(cloth_uv_faces.shape[1] == 4)\n",
    "grip_vertex_idx = sim_result['grip_vertex_idx']\n",
    "assert(0 <= grip_vertex_idx < len(cloth_verts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load canonical data\n",
    "canonical_data = accessor.get_sample_data(\n",
    "    sample_id=meta['meta']['sample_id'],\n",
    "    garment_name=meta['meta']['garment_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute per-cloth-vertex nearest human vertex\n",
    "human_verts = canonical_data['human_verts']\n",
    "human_faces = canonical_data['human_faces']\n",
    "cloth_canonical_verts = canonical_data['garment_verts']\n",
    "cloth_texture = canonical_data['garment_texture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "# TODO: This will have to be heavily modified to work with the dynamics simulations.\n",
    "uviz_fnames = meta['images']['uviz']\n",
    "rgb_fnames = meta['images']['rgb']\n",
    "assert(len(uviz_fnames) == len(rgb_fnames))\n",
    "rows = list()\n",
    "for uviz_fname, rgb_fname in zip(uviz_fnames, rgb_fnames):\n",
    "    uviz_path = sample_dir.joinpath(uviz_fname)\n",
    "    rgb_path = sample_dir.joinpath(rgb_fname)\n",
    "    uviz_dict = read_uviz(str(uviz_path.absolute()), index_dtype=np.uint8)\n",
    "    rgb = skimage.io.imread(str(rgb_path.absolute()))\n",
    "\n",
    "    row = uviz_dict\n",
    "    row['rgb'] = rgb\n",
    "    rows.append(row)\n",
    "images_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat images\n",
    "intrinsic = meta['camera']['intrinsic']\n",
    "extrinsic_arr = np.array(list(meta['camera']['extrinsic_list']))\n",
    "rgb_arr = np.array(list(images_df.rgb))\n",
    "uv_arr = np.array(list(images_df.uv))\n",
    "index_arr = np.array(list(images_df.object_index))\n",
    "# should specify index in meta\n",
    "mask_arr = (index_arr == 1).squeeze()\n",
    "# convert Cycles ray length to CV depth\n",
    "# depth_arr = np.array(list(images_df.depth.apply(\n",
    "#     lambda x: ray_length_to_zbuffer(x, intrinsic))))\n",
    "# in Blender 2.90, Cycle's definition of depth changed to CV depth\n",
    "depth_arr = np.array(list(images_df.depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate point cloud in global frame\n",
    "point_cloud_arr = np.empty(rgb_arr.shape, dtype=np.float16)\n",
    "assert(len(depth_arr) == len(extrinsic_arr))\n",
    "for i in range(len(depth_arr)):\n",
    "    depth = depth_arr[i]\n",
    "    extrinsic = extrinsic_arr[i]\n",
    "    pc_local = zbuffer_to_pcloud(depth, intrinsic)\n",
    "    tx_world_camera = np.linalg.inv(extrinsic)\n",
    "    pc_global = pc_local @ tx_world_camera[:3,:3].T + tx_world_camera[:3, 3]\n",
    "    point_cloud_arr[i] = pc_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract cloth point cloud\n",
    "pc_points = point_cloud_arr[mask_arr]\n",
    "pc_uv = uv_arr[mask_arr]\n",
    "pc_rgb = rgb_arr[mask_arr]\n",
    "pc_sizes = np.sum(mask_arr, (1,2))\n",
    "assert(np.sum(pc_sizes) == len(pc_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute canonical coordinate for point cloud\n",
    "cloth_uv_faces_tri = quads2tris(cloth_uv_faces)\n",
    "cloth_faces_tri = quads2tris(cloth_faces)\n",
    "\n",
    "query_uv = pc_uv\n",
    "target_uv_verts = cloth_uv_verts\n",
    "target_uv_faces = cloth_uv_faces_tri\n",
    "\n",
    "barycentric, proj_face_idx = query_uv_barycentric(pc_uv, cloth_uv_verts, cloth_uv_faces_tri)\n",
    "pc_canonical = barycentric_interpolation(\n",
    "    barycentric, cloth_canonical_verts, cloth_faces_tri[proj_face_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute human/cloth aabb\n",
    "human_aabb = get_aabb(human_verts)\n",
    "cloth_aabb = get_aabb(cloth_canonical_verts)\n",
    "aabb = get_union_aabb(human_aabb, cloth_aabb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to zarr\n",
    "experiment_group = sample_root.require_group(sample_dir.stem, overwrite=False)\n",
    "image_group = experiment_group.require_group('image', overwrite=True)\n",
    "point_cloud_group = experiment_group.require_group('point_cloud', overwrite=True)\n",
    "misc_group = experiment_group.require_group('misc', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write misc arrays\n",
    "misc_data = {\n",
    "    'cloth_verts': cloth_verts.astype(np.float32),\n",
    "    'cloth_faces': cloth_faces.astype(np.uint16),\n",
    "    'cloth_uv_verts': cloth_uv_verts.astype(np.float32),\n",
    "    'cloth_uv_faces': cloth_uv_faces.astype(np.uint16),\n",
    "    'cloth_canonical_verts': cloth_canonical_verts.astype(np.float32),\n",
    "    'human_verts': human_verts.astype(np.float32),\n",
    "    'human_faces': human_faces.astype(np.uint16),\n",
    "    'cloth_aabb': cloth_aabb.astype(np.float32),\n",
    "    'human_aabb': human_aabb.astype(np.float32),\n",
    "    'intrinsic': intrinsic.astype(np.float32),\n",
    "    'extrinsic_list': extrinsic_arr.astype(np.float32),\n",
    "    'cloth_texture': cloth_texture.astype(np.uint8)\n",
    "}\n",
    "for key, data in misc_data.items():\n",
    "    misc_group.array(\n",
    "        name=key, data=data, chunks=data.shape,\n",
    "        compressor=compressor, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write image arrays\n",
    "image_data = {\n",
    "    'rgb': rgb_arr.astype(np.uint8),\n",
    "    'uv': uv_arr.astype(np.float16),\n",
    "    'depth': depth_arr.astype(np.float16),\n",
    "    'mask': np.expand_dims(mask_arr, axis=-1)\n",
    "}\n",
    "for key, data in image_data.items():\n",
    "    image_group.array(\n",
    "        name=key, data=data, chunks=(1,) + data.shape[1:],\n",
    "        compressor=compressor, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write point cloud arrays\n",
    "pc_data = {\n",
    "    'point': pc_points.astype(np.float16),\n",
    "    'uv': pc_uv.astype(np.float16),\n",
    "    'rgb': pc_rgb.astype(np.uint8),\n",
    "    'canonical_point': pc_canonical.astype(np.float16),\n",
    "    'sizes': pc_sizes.astype(np.int64)\n",
    "}\n",
    "for key, data in pc_data.items():\n",
    "    point_cloud_group.array(\n",
    "        name=key, data=data, chunks=data.shape,\n",
    "        compressor=compressor, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set attrs\n",
    "meta_attr = meta['meta']\n",
    "attrs = {\n",
    "    'sample_id': meta_attr['sample_id'],\n",
    "    'garment_name': meta_attr['garment_name'],\n",
    "    'gender': meta_attr['gender'],\n",
    "    'fabric': meta_attr['fabric'],\n",
    "    'grip_vertex_idx': grip_vertex_idx\n",
    "}\n",
    "experiment_group.attrs.put(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some garbage so that when I hit \"run all\" it errors on this cell and halts execution.\n",
    "asdfasdfasdfasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Simulation Images\n",
    "\n",
    "Image arrays:\n",
    "- `depth`\n",
    "- `mask`\n",
    "- `rgb`\n",
    "- `uv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Simulation Point Clouds\n",
    "\n",
    "These point clouds will be generated by using the camera intrinsic, the renders, and the masks from the renders. \n",
    "\n",
    "When saving the point clouds to the Zarr, the point clouds should be translated by the Z offset used to offset the camera. This was done so as to make sure the Tshirt fit in the camera frame across the full dynamics simulation (hopefully).\n",
    "\n",
    "Need the following from the simulation data:\n",
    "- `canonical_point`\n",
    "- `point`\n",
    "- `rgb`\n",
    "- `sizes`\n",
    "- `uv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/Tshirt/samples/00380_Tshirt_509/image</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.hierarchy.Group</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">True</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. members</th><td style=\"text-align: left\">4</td></tr><tr><th style=\"text-align: left\">No. arrays</th><td style=\"text-align: left\">4</td></tr><tr><th style=\"text-align: left\">No. groups</th><td style=\"text-align: left\">0</td></tr><tr><th style=\"text-align: left\">Arrays</th><td style=\"text-align: left\">depth, mask, rgb, uv</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Name        : /Tshirt/samples/00380_Tshirt_509/image\n",
       "Type        : zarr.hierarchy.Group\n",
       "Read-only   : True\n",
       "Store type  : zarr.storage.DirectoryStore\n",
       "No. members : 4\n",
       "No. arrays  : 4\n",
       "No. groups  : 0\n",
       "Arrays      : depth, mask, rgb, uv"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zr['Tshirt/samples/00380_Tshirt_509/image'].info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentative: Add Miscellaneous Info?\n",
    "\n",
    "Misc. Arrays:\n",
    "- `cloth_aabb`\n",
    "- `cloth_canonical_aabb`\n",
    "- `cloth_canonical_verts`\n",
    "- `cloth_faces`\n",
    "- `cloth_texture`\n",
    "- `cloth_uv_faces`\n",
    "- `cloth_uv_verts`\n",
    "- `cloth_verts`\n",
    "- `extrinsic_list`\n",
    "- `human_canonical_aabb`\n",
    "- `human_faces`\n",
    "- `human_verts`\n",
    "- `intrinsic`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/Tshirt/samples/00380_Tshirt_509/misc</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.hierarchy.Group</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">True</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. members</th><td style=\"text-align: left\">13</td></tr><tr><th style=\"text-align: left\">No. arrays</th><td style=\"text-align: left\">13</td></tr><tr><th style=\"text-align: left\">No. groups</th><td style=\"text-align: left\">0</td></tr><tr><th style=\"text-align: left\">Arrays</th><td style=\"text-align: left\">cloth_aabb, cloth_canonical_aabb, cloth_canonical_verts, cloth_faces, cloth_texture, cloth_uv_faces, cloth_uv_verts, cloth_verts, extrinsic_list, human_canonical_aabb, human_faces, human_verts, intrinsic</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Name        : /Tshirt/samples/00380_Tshirt_509/misc\n",
       "Type        : zarr.hierarchy.Group\n",
       "Read-only   : True\n",
       "Store type  : zarr.storage.DirectoryStore\n",
       "No. members : 13\n",
       "No. arrays  : 13\n",
       "No. groups  : 0\n",
       "Arrays      : cloth_aabb, cloth_canonical_aabb, cloth_canonical_verts,\n",
       "            : cloth_faces, cloth_texture, cloth_uv_faces, cloth_uv_verts,\n",
       "            : cloth_verts, extrinsic_list, human_canonical_aabb, human_faces,\n",
       "            : human_verts, intrinsic"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zr['Tshirt/samples/00380_Tshirt_509/misc'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
